{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ab800b",
   "metadata": {},
   "source": [
    "# n2c2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e1f080",
   "metadata": {},
   "source": [
    "## Checking the annotations file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7096d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2c2_ann = [line.strip().split(\"\\t\") for line in open(\"Downloads/data_sample/164726.ann\", \"r\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be78dc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['T1', 'Drug', '1341:1344', 'TPA'], ['T2', 'Route', '1376:1378', 'IV'], ['T3', 'Drug', '1379:1384', 'nitro'], ['T4', 'Drug', '1397:1404', 'heparin'], ['T5', 'Drug', '1406:1413', 'aspirin'], ['T6', 'Reason', '5420:5428', 'diuresis'], ['T7', 'Route', '5434:5436', 'IV'], ['T8', 'Drug', '5437:5442', 'lasix'], ['T9', 'Drug', '5447:5453', 'diuril'], ['T10', 'Reason', '5524:5548', 'hemodynamically unstable']]\n"
     ]
    }
   ],
   "source": [
    "n2c2_result = []\n",
    "for item in n2c2_ann:\n",
    "    words = item[1].split()\n",
    "    try:\n",
    "    # check if the second last word is a number\n",
    "        if words[-2].isdigit() and words[-1].isdigit():\n",
    "            start, end = map(int, [words[-2], words[-1]])\n",
    "            # check if the length of the string in the 3rd position is equal to the difference between the two numbers\n",
    "            if end - start == len(item[2]):\n",
    "                n2c2_result.append([item[0], words[0], f\"{start}:{end}\", item[2]])\n",
    "        \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(n2c2_result[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab6846a",
   "metadata": {},
   "source": [
    "## Merging word annotations and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8077415a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_text(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        return file.read()\n",
    "\n",
    "def load_annotations(file_path):\n",
    "    annotations = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            items = line.strip().split(\"\\t\")\n",
    "            try:\n",
    "                annotations.append([items[0], items[1], items[2].split()])\n",
    "            except:\n",
    "                continue\n",
    "    return annotations\n",
    "\n",
    "def annotated_text(text, annotations):\n",
    "    positions = []\n",
    "    for annotation in annotations:\n",
    "        if annotation[0].startswith(\"T\"):\n",
    "            start, end = map(int, annotation[1].split()[1:])\n",
    "            positions.append((start, end, annotation[1].split(\" \")[0], annotation[2]))\n",
    "\n",
    "    # sort the positions list by start index\n",
    "    positions.sort(key=lambda x: x[0])\n",
    "\n",
    "    annotated_text = \"\"\n",
    "    start = 0\n",
    "    for position in positions:\n",
    "        annotated_text += text[start:position[0]]\n",
    "        annotated_text += f\"<{position[2]}> {str(position[3])} </{position[2]}> \"\n",
    "        start = position[1]\n",
    "    annotated_text += text[start:]\n",
    "    return annotated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c605ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = load_text(\"Downloads/data_sample/164726.txt\")\n",
    "annotations = load_annotations(\"Downloads/data_sample/164726.ann\")\n",
    "txt = annotated_text(text, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "063c8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bart_to_ner(text):\n",
    "    tokens = text.split()\n",
    "    ner_tags = []\n",
    "    entity_start = False\n",
    "    current_entity = \"\"\n",
    "    current_tag = \"0\"\n",
    "    \n",
    "    for token in tokens:\n",
    "        if \"<\" in token and \">\" in token:\n",
    "            if \"/\" in token:\n",
    "                entity_start = False\n",
    "                ner_tags.append((current_entity, current_tag))\n",
    "                current_entity = \"\"\n",
    "                current_tag = \"0\"\n",
    "            else:\n",
    "                entity_start = True\n",
    "                current_tag = token.split(\"<\")[1].split(\">\")[0]\n",
    "        elif entity_start:\n",
    "            current_entity += token + \" \"\n",
    "        else:\n",
    "            ner_tags.append((token, 0))\n",
    "    return ner_tags\n",
    "\n",
    "ner_txt = bart_to_ner(txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24e5ee4",
   "metadata": {},
   "source": [
    "## Turning annotated text into NER annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bfb0f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "nerred_txt = []\n",
    "\n",
    "for i, j in enumerate(ner_txt):\n",
    "    if j[1] == \"ADE\":\n",
    "        words = re.findall(r'\\b\\w+\\b', \"B-\"+j[0])\n",
    "        nerred_txt.append((words[0], j[1]))\n",
    "        for word in words[1:]:\n",
    "            nerred_txt.append((word, \"B-\"+j[1]))\n",
    "    else:\n",
    "        words = re.findall(r'\\b\\w+\\b', j[0])\n",
    "        for word in words:\n",
    "            nerred_txt.append((word, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8723b602",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937 ('metabolic', 'ADE')\n",
      "938 ('acidosis', 'ADE')\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(nerred_txt):\n",
    "    if j[1]!=0:\n",
    "        print(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ee120",
   "metadata": {},
   "source": [
    "## ALL the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d2dea7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_texts_eng=[]\n",
    "for nmbr in range(100035,198407):\n",
    "    try:\n",
    "        text = load_text(f\"Downloads/training_20180910/{nmbr}.txt\")\n",
    "        annotations = load_annotations(f\"Downloads/training_20180910/{nmbr}.ann\")\n",
    "        txt = annotated_text(text, annotations)\n",
    "        ner_txt = bart_to_ner(txt)\n",
    "\n",
    "        nerred_txt = []\n",
    "\n",
    "        for i, j in enumerate(ner_txt):\n",
    "            if j[1] == \"ADE\":\n",
    "                words = re.findall(r'\\b\\w+\\b', \"B-\"+j[0])\n",
    "                nerred_txt.append((words[0], j[1]))\n",
    "                for word in words[1:]:\n",
    "                    nerred_txt.append((word, \"B-\"+j[1]))\n",
    "            else:\n",
    "                words = re.findall(r'\\b\\w+\\b', j[0])\n",
    "                for word in words:\n",
    "                    nerred_txt.append((word, 0))\n",
    "        ner_texts_eng.append(nerred_txt)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e472e397",
   "metadata": {},
   "source": [
    "# Estonian stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c6d9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58510a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tekst= pd.read_csv(\"Downloads/training_data_AD_and_AP_1st_and_2nd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2a331cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def NER_annotate(text):\n",
    "    adr_pattern = r'<adr> (\\w+) <adr>'\n",
    "    annot_pattern= r'<(\\w+)>'\n",
    "\n",
    "    adr_matches = re.findall(adr_pattern, text)\n",
    "    annot_matches=re.findall(annot_pattern, text)\n",
    "\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "    ner_annotated_text = []\n",
    "    for word in words:\n",
    "        if word in adr_matches:\n",
    "            ner_annotated_text.append((word, 'B-ADE'))\n",
    "        elif word in annot_matches:\n",
    "            continue\n",
    "        else:\n",
    "            ner_annotated_text.append((word, 0))\n",
    "\n",
    "    return ner_annotated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7a73ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tekstid= [NER_annotate(tekst.iloc[i][\"paragraph_text\"]) for i in range(len(tekst))][1:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
